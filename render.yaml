# https://render.com/docs/blueprint-spec
services:
  - type: web
    name: rag-legal-assistant
    runtime: python
    plan: free                        # or starter / standard for production

    buildCommand: pip install -r requirements.txt
    startCommand: uvicorn app.main:app --host 0.0.0.0 --port $PORT

    envVars:
      # ── LLM provider (Ollama won't work on Render — use an API) ──
      - key: LLM_PROVIDER
        value: groq                   # or openai / together
      - key: LLM_API_KEY
        sync: false                   # set manually in Render dashboard
      - key: LLM_MODEL
        value: mixtral-8x7b-32768    # Groq model name
      - key: LLM_TEMPERATURE
        value: "0.2"

      # ── Embeddings ────────────────────────────────────────────────
      - key: EMBEDDING_MODEL_NAME
        value: sentence-transformers/all-MiniLM-L6-v2

      # ── Retrieval ─────────────────────────────────────────────────
      - key: RETRIEVER_K
        value: "5"
      - key: CHUNK_SIZE
        value: "1000"
      - key: CHUNK_OVERLAP
        value: "200"

      # ── CORS (add your Render URL here) ────────────────────────────
      - key: ALLOWED_ORIGINS
        value: "https://rag-legal-assistant.onrender.com"
